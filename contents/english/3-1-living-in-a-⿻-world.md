# Living in a ⿻ World

> Until lately the best thing that I was able to think in favor of civilization…was that it made possible the artist, the poet, the philosopher, and the man of science. But I think that is not the greatest thing. Now I believe that the greatest thing is a matter that comes directly home to us all. When it is said that we are too much occupied with the means of living to live, I answer that the chief worth of civilization is just that it makes the means of living more complex; that it calls for great and combined intellectual efforts, instead of simple, uncoordinated ones, in order that the crowd may be fed and clothed and houses and moved from place to place. Because more complex and intense intellectual efforts mean a fuller and richer life. They mean more life. Life is an end in itself, and the only question as to whether it is worth living is whether you have enough of it. — Oliver Wendell Holmes, 1900[^LifeAsJoy]

> (A)re…atoms independent elements of reality? No…as quantum theory shows: they are defined by their…interactions with the rest of the world…(Q)uantum physics may just be the realization that this ubiquitous relational structure of reality continues all the way down…Reality is not a collection of things, it’s a network of processes. — Carlo Rovelli, 2022[^RelationalReality]

Technology follows science. And so if we want to understand ⿻ as a vision of _what our world could become_, we need to start off by understanding ⿻ as a perspective on _how the world already is_. The technocratic and libertarian perspectives are rooted in a science, namely the monist atomism we described in the previous chapter: the belief that a universal set of laws operating on an fundamental set of atoms is the best way to understand the world.

Technocracy has a long history of being justified by science and rationality. The idea of “scientific management” (a.k.a. Taylorism) that became popular in the early 1900s was justified by making analogies between social systems and simple mathematical models, and logic and reason as ways of thinking about them. High modernism in architecture is similarly inspired by the beauty of geometry. Libertarianism also borrows heavily from physics and other sciences: just like particles “take the path of least action”, and evolution maximizes fitness, economic agents “maximize utility”. Every phenomenon in the world, from human societies to the motion of the stars, can, in the monist atomist view, ultimately be reduced to these laws.

These approaches have achieved great successes that cannot be ignored.  Newtonian mechanics explained a range of phenomena and helped inspire the technologies of the industrial revolution.  Darwinism is the foundation of modern biology.  Economics has been the most influential of the social sciences on public policy.  And the Church-Turing vision of “general computation” helped inspire the idea of general-purpose computers that are so broadly used today. 


But, as we have learned in the last century, much greater progress is possible if we transcend the limitations of monist atomism. Gödel’s Theorem undermined the unity and completeness of mathematics and a range of non-Euclidean geometries are now critical to science. Symbiosis, ecology, and extended evolutionary synthesis undermined “survival of the fittest” as the central biological paradigm.  Neuroscience has been reimagined around networks and emergent capabilities.  What all these share is a focus on complexity, emergence, multi-level organization and multidirectional causality rather than the application of a universal set of laws to a single type of atomic entity.

⿻ approaches social systems similarly. A corporation can be viewed as a player in a bigger game, but a corporation is simultaneously itself a game, where employees, shareholders, management and customers are all players, and whose outcomes often do not look anything like a coherent utility function. What's more, many other games intersect:  employees of a corporation are often each influenced through their _other_ relationships with the outside world (e.g. political, social, religious, ethnic), and not only through the corporation itself. Countries too are both games and players, intersected by corporations, religions and much more, and there too we cannot cleanly separate apart actions between countries and actions within a country: the writing of this very book is a complex mix of both in multiple ways.

⿻ is thus heavy with analogies to the last century of natural sciences.  While it is in the very nature of ⿻ to appreciate what can be learned by drawing on this diversity of analogies, it is also useful, to illustrate the values of these, to note a connection between some of the core ideas we discussed above and one of the most robust features of the general sciences of complexity.  In particular, while libertarianism and technocracy can be seen as ideological caricatures, they can also be understood in scientific terms as ever-present threats to complex.

Essentially every complex system, from the flow of fluids to the development of ecosystems  to the functioning of the brain, can exhibit both "chaotic" states (where activity is essentially random) and "orderly" states (where patterns are static and rigid).  There is almost always some parameter (such as heat or the mutation rate) that conditions which state accrues, with chaos happening for high values and order for low values.  When the parameter is very close to the "critical value" of transition between these states, when it sits on what complexity theorists call the "edge of chaos", complex behavior can emerge, forming unpredictable, developing, life-like structures that are neither chaotic nor orderly but instead complex.  This corresponds closely to the idea we highlighted above of a "narrow corridor" between centralizing and anti-social, technocratic and libertarian threats that we have highlighted above.  

As such, ⿻ can take from science the crucial importance of steering towards and widening this narrow corridor, a process complexity scientists all "self-organizing criticality".  In doing so, we can draw on the wisdom of many sciences, ensuring we are not unduly captured by any one set of analogies.

### Mathematics

Nineteenth century mathematics saw the rise of formality: being precise and rigorous about the definitions and properties of mathematical structures that we are using, so as to avoid inconsistencies and mistakes. At the beginning of the 20th century, there was a hope that mathematics could be “solved”, perhaps even giving a precise algorithm for determining the truth or falsity of any mathematical claim. 20th century mathematics, on the other hand, was characterized by much more uncertainty.

- **Gödel's theorem**: a number of mathematical results from the early 20th century, most notably Gödel's theorem, showed that there are fundamental and irreducible ways in which key parts of mathematics cannot be fully solved. Similarly, Church proved that some mathematical problems were “undecidable” by computational processes. This dashed the dream of reducing all of mathematics to computations on basic axioms.
- **Computational complexity**: Even when reductionism is feasible in principle/theory, the computation required to predict higher-level phenomena based on their components (its computational complexity) is so large that performing it is unlikely to be practically relevant. In fact, in some cases, it is believed that the required computation would consume far more resources than could possibly be recovered through the understanding gained by such a reduction. In many real-world use cases, the situation can often be described as a well-studied computational problem where the “optimal” algorithm takes an exponentially large amount of time, and so good-enough “heuristic” algorithms often get used in practice.
- **Sensitivity, chaos, and irreducible uncertainty**: Many even relatively simple systems have been shown to exhibit “chaotic” behavior.  A system is chaotic if a tiny change in the initial conditions translates into radical shifts in its eventual behavior after an extended time has elapsed.  The most famous example is weather systems, where it is often said that a butterfly flapping its wings can make the difference in causing a typhoon half-way across the world weeks later.  In the presence of such chaotic effects, attempts at prediction via reduction require unachievable degrees of precision.  To make matters worse, there are often hard limits to how much precision is feasible, as precise instruments often interfere with the systems, they measure in ways that can lead to important changes due to the sensitivity mentioned previously.
* **Fractals**: many mathematical structures have been shown to have similar patterns at very different scales. A good example of this is the Mandelbrot set, generated by repeatedly squaring then adding the same offset to a complex number:

Geometry and topology, once the province of Euclidean certainties, turned out to admit endless variations, just as the certainties of a flat earth vanished with circumnavigation. Axiomatic systems went from the hope for complete mathematical systems to being proven, by Kurt Gödel, Paul Cohen, and others to be inherently unable to resolve some mathematical problems and necessarily incomplete.  Alonzo Church showed that other mathematical questions were undecidable by any computational process.  Even the pure operations of logic and mathematics, it thus turned out, were nearly as ⿻ as the fields of science we discussed above. To illustrate: 

<img src="https://raw.githubusercontent.com/pluralitybook/plurality/main/figs/science.jpg" width="100%" alt="Science">

**Figure 1: The Mandelbrot Set (characterizing the chaotic behavior of simple quadratic functions depending on parameter values in the function) shown at two scales.  Source: Wikipedia (left) and Stack Overflow (right).**

- **Relationality in mathematics**: in mathematics, different branches are often interconnected, and insights from one area can be applied to another. For instance, algebraic structures are ubiquitous in many branches of mathematics, and they provide a language for expressing and exploring relationships between mathematical objects. The study of algebraic geometry connects these structures to geometry. Moreover, the study of topology is based on understanding the relationships between shapes and their properties. The mix of diversity and interconnectedness is perhaps the defining feature of modern mathematics 

### Physics

At the end of the 19th century, Lord Kelvin infamously proclaimed that “There is nothing new to discover in physics now.”  The next century proved, on the contrary, to be the most fertile and revolutionary in the history of the field.

* **Einstein's theories of relativity** overturned the simplicity of Euclidean geometry and Newtonian dynamics of colliding billiard balls as a guide to understanding the physical world at a very large scale. When objects travel at large fractions of the speed of light, very different rules start describing their behavior.
* **Quantum mechanics and string theory** similarly showed that classical physics is insufficient at very small scales. Bell's Theorem demonstrated clearly that quantum physics cannot even be fully described as a consequence of probability theory and hidden information: rather, a particle can be in a combination (or “superposition”) of two states at the same time, where those two states _cancel each other out_.
* **“Heisenberg’s Uncertainty Principle”** puts a firm upper limit on the precision with which the velocity and position of a particle can even be measured.
* **The three body problem**, now famous after its central role in Liu Cixin's science-fiction series, shows that an interaction of even three bodies, even under simple Newtonian physics, is chaotic enough that its future behavior cannot be predicted with simple mathematical problems. However, we still regularly solve _trillion-body problems_ well enough for everyday use by using seventeenth-century abstractions such as “temperature” and “pressure”.

Perhaps the most striking and consistent feature of the revolutions in twentieth century physics was the way they upset assumptions about a fixed and objective external world.  Relativity showed how time, space, acceleration, and even gravity were functions of the relationship among objects, rather than absolute features of an underlying reality.  Quantum physics went even further, showing that even these relative relationships are not fixed until observed and thus are fundamentally interactions rather than objects.  Thus, modern science often consists of mixing and matching different disciplines to understand different aspects of the physical world at different scales

The applications of this rich and ⿻ understanding of physical reality are at the very core of the tragedies of the twentieth century.  Great powers harnessed the power of the atom to shape world affairs.  Global corporations powered unprecedented communications and intelligence by harnessing their understanding of quantum physics to pack ever-tinier electronics into the palms of their customers’ hands.  The burning of wood and coal by millions of families has become the cause of ecological devastation, political conflict, and world-spanning social movements based on information derived from microscopic sensors scattered around the world.

### Biology

If the defining idea of 19th century macrobiology (concerning advanced organisms and their interactions) was the “natural selection”, the defining idea of the 20th century analog was “ecosystems”.  Where natural selection emphasized the “Darwinian” competition for survival in the face of scarce resources, the ecosystem view (closely related to the idea of “extended evolutionary synthesis”) emphasizes:

- **Limits to predictability of models**: we have continued to discover limits in our ability to make effective models of animal behavior that are based on reductive concepts, such as behaviorism, neuroscience, and so forth, illustrating computational complexity.
- **Similarities between organisms and ecosystems**: we have discovered that many diverse organisms (“ecosystems”) can exhibit features similar to multicellular life (homeostasis, fragility to destruction or over propagation of internal components, etc.) illustrating sensitivity and chaos.
- **Higher-level organisms** that operate through the cooperation of simpler ones (e.g., multicellular life as cooperation among single-celled organisms or “eusocial” organisms like ants from individual insects). A particular property of the evolution of these organisms is the potential for mutation and selection to occur at all these levels, illustrating multi-scale organization.
- **The diversity of cross-species interactions**, including traditional competition or predator and prey relationships, but also a range of “mutualism”, where organisms depend on services provided by other organisms and help sustain them in turn, exemplifying entanglement, and relationality.
- **Epigenetics**: we have discovered that genetics codes only a portion of these behaviors, and “epigenetics” or other environmental features play important roles in evolution and adaptation, illustrating embedded causality.

This shift wasn’t simply a matter of scientific theory.  It led to some of the most important shifts in human behavior and interaction with nature of the 20th century.  In particular, the environmental movement and the efforts it created to protect ecosystems, biodiversity, the ozone layer, and the climate all emerged from and have relied heavily on this science of “ecology”, to the point where this movement is often given that label.

### Neuroscience

Modern neuroscience started in the late 19th century, when Camillo Golgi, Santiago Ramón y Cajal, and collaborators isolated neurons and their electrical activations as the fundamental functional unit of the brain.  This analysis was refined into clear physical models by the work of Hodgkin and Huxley, who built and tested in on animals their electrical theories of nervous communication. More recently, however, we have seen a series of discoveries that put chaos and complexity theory at the core of how the brain functions:

* **Distribution of brain functions**: mathematical modeling, brain imaging, and single-neuron activation experiments suggested that many if not most brain functions are distributed across regions of the brain, emerging from patterns of interactions rather than primarily physical localization.
* **The Hebbian model of connections**, where they are strengthened by repeated co-firing, is perhaps one of the most elegant illustrations of the idea of “relationality” in science, closely paralleling the way we typically imagine human relationships developing
* **Study of artificial neural networks**: As early as the late 1950s, researchers beginning with Frank Rosenblatt built the first “artificial neural network” models of the brain. Neural networks have become the foundation of the recent advances in “artificial intelligence”.  Networks of trillions of nodes, each operating on fairly simple principles inspired by neurons of activation triggered by crossing a threshold determined by a linear combination of inputs, are the backbone of the “foundation models” such as BERT and the GPT models.

### From science to society
	
⿻ is, scientifically, the application of an analogous perspective to the understanding of human societies and, technologically, the attempt to build formal information and governance systems that account for and resemble these structures as physical technologies built on ⿻ science do. Perhaps the crispest articulation of this vision appears in the work of the leading figure of network sociology, Mark Granovetter. There is no basic individual atom; personal identity fundamentally arises from social relationships and connections.  Nor is there any fixed collective or even set of collectives: social groups do and must constantly shift and reconfigure.  This bidirectional equilibrium between the diversity of people and the social groups they create is the essence of ⿻ social science.  

Moreover, these social groups exist at a variety of intersecting and non-hierarchical scales.  Families, clubs, towns, provinces, religious groups of all sizes, businesses at every scale, demographic identities (gender, sexual identity, race, ethnicity, etc.), education and academic training, and many more co-existing and intersecting.  For example, from the perspective of global Catholicism, the US is an important but “minority” country, with only about 6% of all Catholics living in the US; but the same could be said about Catholicism from the perspective of the US, with about 23% of Americans being Catholic. 
 
While we have emphasized the positive vision of ⿻istic social science (a “network society”), it is important to note that beyond its inherent plausibility, a key reason for adopting such a perspective is the impossibility of explaining most social problems using monistic atomism given both complexity and chaos. Even in the social science field, economics, that most consistently aims for “methodological individualism”, it is universally accepted that trying to model complex organizations exclusively as the outgrowth of individual behavior is unpromising.  

The field of Industrial Organization, for example, treats firms rather than individuals as the central actors, while most macroeconomic models assume sufficient homogeneity to allow the construction of a “representative agent”, rather than reducing behavior to actual diverse individual choice.  In fact, one fascinating features of economic models is that they tend to feature a range of different forms of organization as either the “central planner” (e.g., a technology platform operator or provincial government) or as the “individual actors” (e.g., a municipality or a manufacturer).  This is hardly surprising given that a leading result in game theory (the most canonical approach to economic “reduction” of a group to individual behavior) is the “folk theorem”, a variant on chaos and irreducible uncertainty that states that when interactions are repeated, a very wide range of outcomes can be an equilibrium. 

Yet, whatever level of explanation is chosen, actors are almost always modeled as atomistically self-interested and planners as coherent, objective maximizers, rather than socially-embedded intersections of group affiliations.  The essence of understanding social phenomena as arising from a “network society” is to embrace this richness and build social systems, technologies, and policies that harness it, rather than viewing it as a distracting complication.  Such systems need, among other things, to explicitly account for the social nature of motivations, to empower a diversity of social groups, to anticipate and support social dynamism and evolution, to ground personal identity in social affiliations and group choices in collective, democratic participation and to facilitate the establishment and maintenance of social context facilitating community.  

While we do not have the space to review it in detail, a rich literature provides quantitative and social scientific evidence for the explanatory power of the ⿻ perspective [^AssemblageTheory]. Studies of industrial dynamics, of social and behavioral psychology, of economic development, of organizational cohesion, and much else, have shown the central role of social relationships that create and harness diversity[^SocialDynamics].   Instead, we will pull out just one example that perhaps will be both the most surprising and most related to the scientific themes above: the evolution of scientific knowledge itself.

A growing interdisciplinary academic field of “Science of Science” (SciSci) studies the emergence of scientific knowledge as a complex system from networks among scientists and ideas [^SciSciField]. It charts the emergence and proliferation of scientific fields, sources of scientific novelty and progress, the strategies of exploration scientists choose, and the impact of social structure on intellectual advance. Among other things, they find that scientific exploration is biased towards topics that have been frequently discussed within a field and constrained by social and institutional connections among scientists, which diminishes the efficiency of the scientific knowledge discovery process [^TopicBiasInScience]. Furthermore, they discover that a decentralized scientific community, made up of mostly independent, non-overlapping teams that use a variety of methods and draw upon a broad spectrum of earlier publications, tends to yield more reliable scientific knowledge. In contrast, centralized communities marked by repeated collaborations and restricted to a limited range of approaches from previous studies are likely to generate less reliable outcomes [^CentralizedScientificCommunity] [^PredictRobustScience] It also finds strong connections between research team size and hierarchy with the types of findings (risky and revolutionary v. normal science) developed and documents the increasingly dominant role of teams (as opposed to individual research) in modern science [^TeamScience]. Although the largest innovations tend to arise from a strong grounding in existing disciplines deployed in unusual and surprising combinations [^DisconnectionDiscordInnovation] [^SurpriseInnovation] [^ScientificInnovation], it illustrates that most incentive structures used in science (based e.g. on publication quality and citation count) create perverse incentives that limit scientific creativity. These findings have led to the development of new metrics in scientific communities that can reward innovations and offset these biases, creating a more ⿻istic incentive set [^ScienceMetrics].

Science policy research that directly accounts for and enhances ⿻ity in science demonstrates advantages for both the firmness of existing knowledge and the discovery of novel insights. When more distinct communities and their approaches work to validate existing claims, those _independent_ perspectives ensure their findings are more robust to rebuttal and revision. Moreover, when building artificial intelligences based on ⿻ity principles by simulating the diversity we see in the most ⿻istic scientific ventures, AI-driven discoveries exceed those produced by normal human science [^AccelerateScienceAI].

Thus, even in understanding the very practice of science, a ⿻ perspective, grounded in many intersecting levels of social organization, is critical. Science of science findings regarding the driving forces behind the emergence of disruptive, innovative knowledge have been replicated in other communities of creative collaboration, such as patents and software projects in GitHub, revealing that a ⿻ outlook could transcend the advance of science and technology of any flavor.


**A future ⿻?**


Yet the assumptions on which the Technocratic and Libertarian visions of the future discussed above diverge sharply from such ⿻ foundations.  

In the technocratic vision we discussed in the previous chapter, the “messiness” of existing administrative systems is to be replaced by a massive-scale, unified, rational, scientific, artificially intelligent planning system.  Transcending locality and social diversity, this unified agent is imagined to give “unbiased” answers to any economic and social problem, transcending social cleavages and differences.  As such, it seeks to at best paper over and at worst erase, rather than fostering and harnessing, the social diversity and heterogeneity that ⿻ social science sees as defining the very objects of interest, engagement, and value.

In the libertarian vision, the sovereignty of the atomistic individual (or in some versions, a homogeneous and tightly aligned group of individuals) is the central aspiration.  Social relations are best understood in terms of “customers”, “exit” and other capitalist dynamics.  Democracy and other means of coping with diversity are viewed as failure modes for systems that do not achieve sufficient alignment and freedom.  

But these cannot be the only paths forward.  ⿻ science has shown us the power of harnessing a ⿻ understanding of the world to build physical technology.  We have to ask what a society and information technology built on an analogous understanding of human societies would look like.  Luckily, the twentieth century saw the systematic development of such a vision, from philosophical and social scientific foundations to the beginnings of technological expression.  While that path (dao) of development is today somewhat forgotten, we will rediscover it in the next chapter.


[^LifeAsJoy]: Harper’s Magazine. “Holmes – Life as Art,” May 2, 2009. https://harpers.org/2009/05/holmes-life-as-art/.
[^RelationalReality]: Carlo Rovelli, “The Big Idea: Why Relationships Are the Key to Existence.” The Guardian, September 5, 2022, sec. Books. https://www.theguardian.com/books/2022/sep/05/the-big-idea-why-relationships-are-the-key-to-existence.
[^MultilevelSelection]: David Wilson, Mark Vugt, and Rick O’Gorman, “Multilevel Selection Theory and Major Evolutionary Transitions.” _Current Directions in Psychological Science_ 17, no. 1 (February 2008): 6–9. https://doi.org/10.1111/j.1467-8721.2008.00538.x.
[^NeuroscienceComplexity]: Here are some examples of these properties in neuroscience: **Sensitivity**: In neuroscience, sensitivity refers to the ability of the brain to detect and respond to small changes in its environment. One example of sensitivity in the brain is the phenomenon of synaptic plasticity, which is the ability of synapses (connections between neurons) to change in strength in response to activity. This sensitivity allows the brain to adapt and learn from experience. **Chaos**: Chaos is a property of complex systems that exhibit unpredictable behavior even though they are deterministic. In neuroscience, chaos has been observed in the activity of neurons in the brain. For example, studies have shown that the firing patterns of individual neurons can be highly irregular and chaotic, with no discernible pattern or rhythm. This chaotic activity may play a role in information processing and communication within the brain. **Sensitivity and chaos together:** Sensitivity and chaos can also interact in the brain to produce complex and adaptive behavior. For example, studies have shown that the brain can exhibit sensitivity to small changes in sensory input, but this sensitivity can also lead to chaotic activity in neural networks. However, this chaotic activity can be controlled and harnessed to produce adaptive behavior, such as in the case of motor control and coordination. The brain's ability to integrate sensitivity and chaos in this way is a hallmark of its remarkable complexity and adaptability. 
[^AssemblageTheory]: In assemblage theory, as articulated by Manuel DeLanda, entities are understood as complex structures formed from the symbiotic relationship between heterogeneous components, rather than being reducible to their individual parts. Its central thesis is that people do not act exclusively by themselves, and instead human action requires complex socio-material interdependencies. DeLanda's perspective shifts the focus from inherent qualities of entities to the dynamic processes and interactions that give rise to emergent properties within networks of relations.  His book "A New Philosophy of Society: Assemblage Theory and Social Complexity" (2006) is a good starting point. 
[^SocialDynamics]: Scott Page, _The Difference: How the Power of Diversity Creates Better Groups, Firms, Schools, and Societies_, (Princeton: Princeton University Press, 2007; César Hidalgo, _Why Information Grows: The Evolution of Order, from Atoms to Economies_, (New York: Basic Books, 2015); Daron Acemoglu, and Joshua Linn, “Market Size in Innovation: Theory and Evidence from the Pharmaceutical Industry,” _Library Union Catalog of Bavaria_, (Berlin and Brandenburg: B3Kat Repository, October 1, 2003), https://doi.org/10.3386/w10038;  Mark Granovetter, “The Strength of Weak Ties,” _American Journal of Sociology_ 78, no. 6 (May 1973): 1360–80; Brian Uzzi, “Social Structure and Competition in Interfirm Networks: The Paradox of Embeddedness,” Administrative Science Quarterly 42, no. 1 (March 1997): 35–67. https://doi.org/10.2307/2393808; Jonathan Michie, and Ronald S. Burt, “Structural Holes: The Social Structure of Competition,” _The Economic Journal_ 104, no. 424 (May 1994): 685. https://doi.org/10.2307/2234645; McPherson, Miller, Lynn Smith-Lovin, and James M Cook. “Birds of a Feather: Homophily in Social Networks.” Annual Review of Sociology 27, no. 1 (August 2001): 415–44.
[^TopicBiasInScience]: Andrey Rzhetsky, Jacob Foster, Ian Foster, and James Evans, “Choosing Experiments to Accelerate Collective Discovery,” _Proceedings of the National Academy of Sciences_ 112, no. 47 (November 9, 2015): 14569–74. https://doi.org/10.1073/pnas.1509757112.
[^CentralizedScientificCommunity]: Valentin Danchev, Andrey Rzhetsky, and James A Evans, “Centralized Scientific Communities Are Less Likely to Generate Replicable Results.” _ELife_ 8 (July 2, 2019), https://doi.org/10.7554/elife.43094.
[^PredictRobustScience]: Alexander Belikov, Andrey Rzhetsky, and James Evans, "Prediction of robust scientific facts from literature," _Nature Machine Intelligence_ 4.5 (2022): 445-454.
[^TeamScience]: Lingfei Wu, Dashun Wang, and James Evans, "Large teams develop and small teams disrupt science and technology," _Nature_ 566.7744 (2019): 378-382.
[^DisconnectionDiscordInnovation]: Yiling Lin, James Evans, and Lingfei Wu, "New directions in science emerge from disconnection and discord," _Journal of Informetrics_ 16.1 (2022): 101234.
[^SurpriseInnovation]: Feng Shi, and James Evans, "Surprising combinations of research contents and contexts are related to impact and emerge with scientific outsiders from distant disciplines," Nature Communications 14.1 (2023): 1641.
[^ScientificInnovation]: Jacob Foster, Andrey Rzhetsky, and James A. Evans, "Tradition and Innovation in Scientists’ Research Strategies," _American Sociological Review_ 80.5 (2015): 875-908.
[^ScienceMetrics]: Aaron Clauset, Daniel Larremore, and Roberta Sinatra, "Data-driven predictions in the science of science," _Science_ 355.6324 (2017): 477-480.
[^AccelerateScienceAI]: Jamshid Sourati, and James Evans, "Accelerating science with human-aware artificial intelligence," _Nature Human Behaviour_ 7.10 (2023): 1682-1696.
[^SciSciField]: (Foot note in text with no actual foot note - so I added but someone needs to put in the actual reference that was intended.)
